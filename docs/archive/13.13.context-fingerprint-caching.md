# Story 13.13: Context Fingerprint Caching

## Status
Draft

## Story
**As a** FairForm developer,
**I want** context fingerprint caching to optimize AI prompt generation,
**so that** repeated requests with identical context are served from cache instead of rebuilding prompts.

## Acceptance Criteria

1. Context fingerprints are generated consistently for identical context data
2. Cache stores prepared prompts keyed by context fingerprint
3. Cache hit rate is monitored and optimized
4. Cache automatically invalidates when context changes
5. Cache supports TTL (time-to-live) for automatic expiration
6. Cache handles memory limits and eviction policies
7. System falls back gracefully when cache is unavailable
8. Unit tests cover caching logic and invalidation scenarios

## Tasks / Subtasks

- [ ] Task 1: Create context fingerprint cache service (AC: 1, 2)
  - [ ] Create `lib/ai/contextCache.ts`
  - [ ] Implement fingerprint-based cache storage
  - [ ] Add cache key generation logic
  - [ ] Support multiple cache backends (memory, Redis)
  - [ ] Add cache statistics and monitoring

- [ ] Task 2: Implement cache storage and retrieval (AC: 2, 5)
  - [ ] Create cache storage interface
  - [ ] Implement memory-based cache with LRU eviction
  - [ ] Add TTL support for automatic expiration
  - [ ] Handle cache serialization/deserialization
  - [ ] Add cache size limits and monitoring

- [ ] Task 3: Add cache invalidation logic (AC: 4)
  - [ ] Implement context change detection
  - [ ] Add fingerprint-based invalidation
  - [ ] Handle partial cache invalidation
  - [ ] Add cache warming strategies
  - [ ] Implement cache refresh mechanisms

- [ ] Task 4: Integrate with prompt generation (AC: 2)
  - [ ] Modify context builder to use cache
  - [ ] Add cache lookup before prompt generation
  - [ ] Store generated prompts in cache
  - [ ] Handle cache misses gracefully
  - [ ] Add cache performance logging

- [ ] Task 5: Add cache monitoring and metrics (AC: 3, 7)
  - [ ] Track cache hit/miss ratios
  - [ ] Monitor cache size and memory usage
  - [ ] Add cache performance metrics
  - [ ] Implement cache health checks
  - [ ] Add cache debugging utilities

- [ ] Task 6: Implement fallback mechanisms (AC: 7)
  - [ ] Add graceful degradation when cache fails
  - [ ] Implement cache bypass options
  - [ ] Handle cache corruption scenarios
  - [ ] Add emergency cache clearing
  - [ ] Ensure system continues working without cache

- [ ] Task 7: Add configuration management (AC: 5, 6)
  - [ ] Create cache configuration options
  - [ ] Add environment-based cache settings
  - [ ] Implement cache size limits
  - [ ] Add TTL configuration options
  - [ ] Support cache backend selection

- [ ] Task 8: Create comprehensive tests (AC: 8)
  - [ ] Test cache storage and retrieval
  - [ ] Test cache invalidation scenarios
  - [ ] Test TTL expiration behavior
  - [ ] Test fallback mechanisms
  - [ ] Test performance under load

## Dev Notes

### Architecture Context
[Source: docs/epic-13-unified-architecture-specification.md]

Context fingerprint caching is **essential for performance** - it prevents redundant prompt generation for identical contexts. The system uses **SHA-256 fingerprints** as cache keys with intelligent invalidation when context changes.

**Key Design Decisions:**
- SHA-256 fingerprints for cache keys
- LRU eviction with configurable size limits
- TTL-based automatic expiration
- Graceful fallback when cache unavailable
- Comprehensive monitoring and metrics

### Cache Architecture

**Cache Interface:**
```typescript
interface ContextCache {
  get(fingerprint: string): Promise<CachedPrompt | null>;
  set(fingerprint: string, prompt: string, ttl?: number): Promise<void>;
  invalidate(fingerprint: string): Promise<void>;
  clear(): Promise<void>;
  getStats(): CacheStats;
}

interface CachedPrompt {
  prompt: string;
  fingerprint: string;
  cachedAt: number;
  expiresAt: number;
  accessCount: number;
  lastAccessed: number;
}

interface CacheStats {
  hits: number;
  misses: number;
  hitRate: number;
  size: number;
  maxSize: number;
  memoryUsage: number;
  evictions: number;
}
```

### Fingerprint Generation

**Consistent Fingerprinting:**
```typescript
import crypto from 'crypto';

class ContextFingerprinter {
  generateFingerprint(context: AIPromptContext): string {
    // Create deterministic hash from context data
    const fingerprintData = {
      caseType: context.case?.caseType,
      jurisdiction: context.case?.jurisdiction,
      currentStepOrder: context.case?.currentStepOrder,
      progressPct: context.case?.progressPct,
      userPrefs: context.user?.preferences,
      summary: context.summary,
      // Exclude timestamps and dynamic data
    };
    
    // Sort object keys for consistent hashing
    const sortedData = this.sortObjectKeys(fingerprintData);
    
    return crypto
      .createHash('sha256')
      .update(JSON.stringify(sortedData))
      .digest('hex');
  }
  
  private sortObjectKeys(obj: any): any {
    if (obj === null || typeof obj !== 'object') {
      return obj;
    }
    
    if (Array.isArray(obj)) {
      return obj.map(item => this.sortObjectKeys(item));
    }
    
    const sortedKeys = Object.keys(obj).sort();
    const sortedObj: any = {};
    
    sortedKeys.forEach(key => {
      sortedObj[key] = this.sortObjectKeys(obj[key]);
    });
    
    return sortedObj;
  }
}
```

### Cache Implementation

**Memory-Based Cache:**
```typescript
class MemoryContextCache implements ContextCache {
  private cache = new Map<string, CachedPrompt>();
  private accessOrder = new Map<string, number>();
  private stats: CacheStats;
  private maxSize: number;
  private defaultTTL: number;
  
  constructor(maxSize: number = 1000, defaultTTL: number = 300000) { // 5 minutes
    this.maxSize = maxSize;
    this.defaultTTL = defaultTTL;
    this.stats = {
      hits: 0,
      misses: 0,
      hitRate: 0,
      size: 0,
      maxSize,
      memoryUsage: 0,
      evictions: 0
    };
  }
  
  async get(fingerprint: string): Promise<CachedPrompt | null> {
    const cached = this.cache.get(fingerprint);
    
    if (!cached) {
      this.stats.misses++;
      this.updateHitRate();
      return null;
    }
    
    // Check if expired
    if (Date.now() > cached.expiresAt) {
      this.cache.delete(fingerprint);
      this.accessOrder.delete(fingerprint);
      this.stats.misses++;
      this.updateHitRate();
      return null;
    }
    
    // Update access tracking
    cached.accessCount++;
    cached.lastAccessed = Date.now();
    this.accessOrder.set(fingerprint, Date.now());
    
    this.stats.hits++;
    this.updateHitRate();
    
    return cached;
  }
  
  async set(fingerprint: string, prompt: string, ttl?: number): Promise<void> {
    const now = Date.now();
    const expiresAt = now + (ttl || this.defaultTTL);
    
    const cached: CachedPrompt = {
      prompt,
      fingerprint,
      cachedAt: now,
      expiresAt,
      accessCount: 0,
      lastAccessed: now
    };
    
    // Evict if cache is full
    if (this.cache.size >= this.maxSize) {
      await this.evictLRU();
    }
    
    this.cache.set(fingerprint, cached);
    this.accessOrder.set(fingerprint, now);
    
    this.stats.size = this.cache.size;
    this.updateMemoryUsage();
  }
  
  private async evictLRU(): Promise<void> {
    if (this.cache.size === 0) return;
    
    // Find least recently used item
    let oldestFingerprint = '';
    let oldestTime = Date.now();
    
    for (const [fingerprint, accessTime] of this.accessOrder) {
      if (accessTime < oldestTime) {
        oldestTime = accessTime;
        oldestFingerprint = fingerprint;
      }
    }
    
    // Remove from cache
    this.cache.delete(oldestFingerprint);
    this.accessOrder.delete(oldestFingerprint);
    
    this.stats.evictions++;
    this.stats.size = this.cache.size;
  }
  
  private updateHitRate(): void {
    const total = this.stats.hits + this.stats.misses;
    this.stats.hitRate = total > 0 ? this.stats.hits / total : 0;
  }
  
  private updateMemoryUsage(): void {
    // Rough estimation of memory usage
    let totalSize = 0;
    for (const [key, value] of this.cache) {
      totalSize += key.length * 2; // UTF-16
      totalSize += value.prompt.length * 2;
      totalSize += 100; // Overhead for object
    }
    this.stats.memoryUsage = totalSize;
  }
}
```

### Cache Integration

**Context Builder Integration:**
```typescript
class CachedContextBuilder {
  private cache: ContextCache;
  private fingerprinter: ContextFingerprinter;
  
  constructor(cache: ContextCache) {
    this.cache = cache;
    this.fingerprinter = new ContextFingerprinter();
  }
  
  async buildContextWithCache(
    userId: string,
    caseId?: string,
    sessionId?: string
  ): Promise<AIPromptContext> {
    // Build base context
    const context = await this.buildBaseContext(userId, caseId, sessionId);
    
    // Generate fingerprint
    const fingerprint = this.fingerprinter.generateFingerprint(context);
    
    // Check cache
    const cachedPrompt = await this.cache.get(fingerprint);
    
    if (cachedPrompt) {
      console.log(`Cache hit for fingerprint: ${fingerprint}`);
      context.cachedPrompt = cachedPrompt.prompt;
      context.cacheHit = true;
      return context;
    }
    
    console.log(`Cache miss for fingerprint: ${fingerprint}`);
    
    // Generate prompt
    const prompt = await this.generatePrompt(context);
    
    // Cache the result
    await this.cache.set(fingerprint, prompt);
    
    context.cachedPrompt = prompt;
    context.cacheHit = false;
    
    return context;
  }
  
  async invalidateContext(userId: string, caseId?: string): Promise<void> {
    // Generate fingerprint for current context
    const context = await this.buildBaseContext(userId, caseId);
    const fingerprint = this.fingerprinter.generateFingerprint(context);
    
    // Invalidate cache entry
    await this.cache.invalidate(fingerprint);
    
    console.log(`Invalidated cache for fingerprint: ${fingerprint}`);
  }
}
```

### Cache Invalidation

**Smart Invalidation:**
```typescript
class CacheInvalidator {
  private cache: ContextCache;
  private fingerprinter: ContextFingerprinter;
  
  constructor(cache: ContextCache) {
    this.cache = cache;
    this.fingerprinter = new ContextFingerprinter();
  }
  
  async handleContextChange(
    changeType: 'case_update' | 'step_change' | 'user_pref_change',
    userId: string,
    caseId?: string
  ): Promise<void> {
    console.log(`Handling context change: ${changeType} for user ${userId}, case ${caseId}`);
    
    // Generate new fingerprint
    const newContext = await this.buildContext(userId, caseId);
    const newFingerprint = this.fingerprinter.generateFingerprint(newContext);
    
    // Invalidate old cache entries that might be affected
    await this.invalidateRelatedEntries(changeType, userId, caseId);
    
    // Optionally pre-warm cache with new context
    await this.preWarmCache(newContext, newFingerprint);
  }
  
  private async invalidateRelatedEntries(
    changeType: string,
    userId: string,
    caseId?: string
  ): Promise<void> {
    // This is a simplified implementation
    // In practice, you might maintain a mapping of fingerprints to contexts
    // for more targeted invalidation
    
    const patterns = this.getInvalidationPatterns(changeType, userId, caseId);
    
    for (const pattern of patterns) {
      await this.cache.invalidate(pattern);
    }
  }
  
  private getInvalidationPatterns(
    changeType: string,
    userId: string,
    caseId?: string
  ): string[] {
    const patterns: string[] = [];
    
    switch (changeType) {
      case 'case_update':
        if (caseId) {
          patterns.push(`case:${caseId}:*`);
        }
        break;
      case 'user_pref_change':
        patterns.push(`user:${userId}:*`);
        break;
      case 'step_change':
        if (caseId) {
          patterns.push(`case:${caseId}:step:*`);
        }
        break;
    }
    
    return patterns;
  }
}
```

### Cache Monitoring

**Metrics and Health Checks:**
```typescript
class CacheMonitor {
  private cache: ContextCache;
  private healthCheckInterval: NodeJS.Timeout;
  
  constructor(cache: ContextCache) {
    this.cache = cache;
    this.startHealthChecks();
  }
  
  private startHealthChecks(): void {
    // Run health checks every 5 minutes
    this.healthCheckInterval = setInterval(() => {
      this.performHealthCheck();
    }, 5 * 60 * 1000);
  }
  
  private async performHealthCheck(): Promise<void> {
    const stats = this.cache.getStats();
    
    console.log('Cache Health Check:', {
      timestamp: new Date().toISOString(),
      stats
    });
    
    // Alert if hit rate is too low
    if (stats.hitRate < 0.3 && stats.hits + stats.misses > 100) {
      console.warn(`Low cache hit rate: ${(stats.hitRate * 100).toFixed(1)}%`);
    }
    
    // Alert if memory usage is high
    if (stats.memoryUsage > 50 * 1024 * 1024) { // 50MB
      console.warn(`High cache memory usage: ${(stats.memoryUsage / 1024 / 1024).toFixed(1)}MB`);
    }
  }
  
  getDetailedStats(): DetailedCacheStats {
    const baseStats = this.cache.getStats();
    
    return {
      ...baseStats,
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      memoryUsage: process.memoryUsage(),
      performance: {
        averageResponseTime: this.calculateAverageResponseTime(),
        peakMemoryUsage: this.getPeakMemoryUsage()
      }
    };
  }
}
```

### Source Tree
```
lib/ai/
├── contextCache.ts        # NEW: Cache implementation
├── contextFingerprinter.ts # NEW: Fingerprint generation
├── cacheInvalidator.ts    # NEW: Cache invalidation
├── cacheMonitor.ts        # NEW: Monitoring and metrics
└── contextBuilder.ts      # MODIFIED: Add cache integration
```

### Testing

**Test Location:** `lib/ai/contextCache.test.ts`

**Test Coverage:**
- Cache storage and retrieval
- Fingerprint generation consistency
- Cache invalidation scenarios
- TTL expiration behavior
- LRU eviction policy
- Performance under load

**Example Test:**
```typescript
describe('ContextCache', () => {
  it('stores and retrieves cached prompts', async () => {
    const cache = new MemoryContextCache();
    const fingerprint = 'test-fingerprint';
    const prompt = 'Test prompt content';
    
    await cache.set(fingerprint, prompt);
    const retrieved = await cache.get(fingerprint);
    
    expect(retrieved).toBeTruthy();
    expect(retrieved!.prompt).toBe(prompt);
  });
  
  it('generates consistent fingerprints for identical contexts', () => {
    const fingerprinter = new ContextFingerprinter();
    
    const context1: AIPromptContext = {
      case: { caseType: 'eviction', jurisdiction: 'CA' },
      summary: 'Test summary'
    };
    
    const context2: AIPromptContext = {
      case: { caseType: 'eviction', jurisdiction: 'CA' },
      summary: 'Test summary'
    };
    
    const fingerprint1 = fingerprinter.generateFingerprint(context1);
    const fingerprint2 = fingerprinter.generateFingerprint(context2);
    
    expect(fingerprint1).toBe(fingerprint2);
  });
});
```

### Performance Considerations
- Use efficient hash algorithms for fingerprints
- Implement LRU eviction to manage memory
- Monitor cache hit rates and optimize
- Consider Redis for distributed caching
- Add cache warming strategies

### Dependencies
- crypto (Node.js built-in)
- contextBuilder from Story 13.3
- contextSnapshot from Story 13.10

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-13 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent*

### Debug Log References
_To be populated by dev agent*

### Completion Notes List
_To be populated by dev agent*

### File List
_To be populated by dev agent*

## QA Results
_To be populated by QA agent*
