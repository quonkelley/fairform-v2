# Story 13.12: Session Lifecycle Management

## Status
Draft

## Story
**As a** FairForm system administrator,
**I want** automated session lifecycle management with archiving and cleanup,
**so that** the system maintains optimal performance and storage efficiency.

## Acceptance Criteria

1. System automatically archives sessions after 7 days of inactivity (prod) or 24 hours (demo)
2. Archived sessions are deleted after 90 days (prod) or 14 days (demo)
3. Cleanup process runs daily via scheduled job
4. System handles cleanup failures gracefully with retry logic
5. Cleanup process logs all operations for monitoring
6. System preserves active sessions and recent activity
7. Cleanup respects demo/production data isolation
8. Unit tests cover lifecycle management scenarios

## Tasks / Subtasks

- [ ] Task 1: Create session lifecycle service (AC: 1, 2)
  - [ ] Create `lib/ai/sessionLifecycle.ts`
  - [ ] Implement archiveOldSessions function
  - [ ] Implement deleteExpiredSessions function
  - [ ] Add configurable retention periods
  - [ ] Handle different rules for demo vs production

- [ ] Task 2: Implement scheduled cleanup job (AC: 3, 5)
  - [ ] Create Vercel Cron job or Cloud Function
  - [ ] Schedule daily execution at 2 AM UTC
  - [ ] Add comprehensive logging for all operations
  - [ ] Implement error handling and retry logic
  - [ ] Add monitoring and alerting for failures

- [ ] Task 3: Add session archiving logic (AC: 1, 6)
  - [ ] Check lastMessageAt timestamp for inactivity
  - [ ] Update session status to 'archived'
  - [ ] Preserve session data for potential recovery
  - [ ] Add archiving timestamp to session metadata
  - [ ] Handle batch archiving operations

- [ ] Task 4: Implement session deletion logic (AC: 2, 7)
  - [ ] Check archivedAt timestamp for expiration
  - [ ] Delete session and all associated messages
  - [ ] Handle cascading deletion of subcollections
  - [ ] Add deletion confirmation and logging
  - [ ] Implement soft delete option for debugging

- [ ] Task 5: Add error handling and retries (AC: 4)
  - [ ] Implement exponential backoff for failures
  - [ ] Add circuit breaker pattern for repeated failures
  - [ ] Handle partial batch operation failures
  - [ ] Add recovery mechanisms for interrupted operations
  - [ ] Log all errors with context

- [ ] Task 6: Create monitoring and alerting (AC: 5)
  - [ ] Add metrics for sessions archived/deleted
  - [ ] Track cleanup job execution time
  - [ ] Monitor storage usage trends
  - [ ] Add alerts for cleanup failures
  - [ ] Create dashboard for lifecycle metrics

- [ ] Task 7: Add configuration management (AC: 1, 2)
  - [ ] Create environment-based configuration
  - [ ] Add runtime configuration updates
  - [ ] Implement feature flags for cleanup
  - [ ] Add emergency stop mechanisms
  - [ ] Document configuration options

- [ ] Task 8: Create comprehensive tests (AC: 8)
  - [ ] Test archiving with various session states
  - [ ] Test deletion with different retention periods
  - [ ] Test error handling scenarios
  - [ ] Test batch operation performance
  - [ ] Mock external dependencies

## Dev Notes

### Architecture Context
[Source: docs/epic-13-unified-architecture-specification.md]

Session lifecycle management is **critical for system health** - it prevents storage bloat while preserving important conversation data. The system uses **automated archiving and cleanup** with different retention periods for demo and production environments.

**Key Design Decisions:**
- Automated daily cleanup via scheduled jobs
- Different retention periods for demo vs production
- Graceful error handling with retry logic
- Comprehensive logging and monitoring
- Batch operations for efficiency

### Lifecycle Configuration

**Retention Periods:**
```typescript
interface LifecycleConfig {
  // Production settings
  prod: {
    archiveAfterDays: 7;        // Archive after 7 days of inactivity
    deleteAfterDays: 90;        // Delete archived after 90 days
    maxActiveSessions: 10000;   // Soft limit for monitoring
  };
  
  // Demo settings
  demo: {
    archiveAfterDays: 1;        // Archive after 1 day of inactivity
    deleteAfterDays: 14;        // Delete archived after 14 days
    maxActiveSessions: 1000;    // Lower limit for demo
  };
  
  // Global settings
  global: {
    cleanupSchedule: '0 2 * * *';  // Daily at 2 AM UTC
    batchSize: 100;                // Process 100 sessions per batch
    retryAttempts: 3;              // Max retry attempts
    retryDelay: 5000;              // 5 second retry delay
  };
}
```

### Session Archiving

**Archive Logic:**
```typescript
class SessionLifecycleManager {
  private config: LifecycleConfig;
  
  constructor() {
    this.config = this.loadConfig();
  }
  
  async archiveOldSessions(): Promise<ArchiveResult> {
    const startTime = Date.now();
    const result: ArchiveResult = {
      archived: 0,
      errors: 0,
      duration: 0
    };
    
    try {
      // Get sessions eligible for archiving
      const cutoffTime = Date.now() - (this.getArchiveAfterDays() * 24 * 60 * 60 * 1000);
      
      const sessions = await aiSessionsRepo.getSessionsForArchiving(cutoffTime);
      
      console.log(`Found ${sessions.length} sessions eligible for archiving`);
      
      // Process in batches
      const batches = this.createBatches(sessions, this.config.global.batchSize);
      
      for (const batch of batches) {
        const batchResult = await this.processArchiveBatch(batch);
        result.archived += batchResult.archived;
        result.errors += batchResult.errors;
      }
      
      result.duration = Date.now() - startTime;
      
      console.log(`Archive completed: ${result.archived} archived, ${result.errors} errors, ${result.duration}ms`);
      
      return result;
      
    } catch (error) {
      console.error('Archive operation failed:', error);
      result.errors++;
      result.duration = Date.now() - startTime;
      return result;
    }
  }
  
  private async processArchiveBatch(sessions: AISession[]): Promise<ArchiveResult> {
    const result: ArchiveResult = { archived: 0, errors: 0, duration: 0 };
    
    for (const session of sessions) {
      try {
        await aiSessionsRepo.updateSession(session.id, {
          status: 'archived',
          archivedAt: Date.now(),
          updatedAt: Date.now()
        });
        
        result.archived++;
        
      } catch (error) {
        console.error(`Failed to archive session ${session.id}:`, error);
        result.errors++;
      }
    }
    
    return result;
  }
}
```

### Session Deletion

**Deletion Logic:**
```typescript
async deleteExpiredSessions(): Promise<DeleteResult> {
  const startTime = Date.now();
  const result: DeleteResult = {
    deleted: 0,
    errors: 0,
    duration: 0
  };
  
  try {
    // Get archived sessions eligible for deletion
    const cutoffTime = Date.now() - (this.getDeleteAfterDays() * 24 * 60 * 60 * 1000);
    
    const archivedSessions = await aiSessionsRepo.getArchivedSessionsForDeletion(cutoffTime);
    
    console.log(`Found ${archivedSessions.length} archived sessions eligible for deletion`);
    
    // Process in batches
    const batches = this.createBatches(archivedSessions, this.config.global.batchSize);
    
    for (const batch of batches) {
      const batchResult = await this.processDeleteBatch(batch);
      result.deleted += batchResult.deleted;
      result.errors += batchResult.errors;
    }
    
    result.duration = Date.now() - startTime;
    
    console.log(`Deletion completed: ${result.deleted} deleted, ${result.errors} errors, ${result.duration}ms`);
    
    return result;
    
  } catch (error) {
    console.error('Deletion operation failed:', error);
    result.errors++;
    result.duration = Date.now() - startTime;
    return result;
  }
}

private async processDeleteBatch(sessions: AISession[]): Promise<DeleteResult> {
  const result: DeleteResult = { deleted: 0, errors: 0, duration: 0 };
  
  for (const session of sessions) {
    try {
      // Delete messages subcollection first
      await this.deleteSessionMessages(session.id);
      
      // Delete session document
      await aiSessionsRepo.deleteSession(session.id);
      
      result.deleted++;
      
    } catch (error) {
      console.error(`Failed to delete session ${session.id}:`, error);
      result.errors++;
    }
  }
  
  return result;
}

private async deleteSessionMessages(sessionId: string): Promise<void> {
  // Delete all messages in the subcollection
  const messagesQuery = db
    .collection('aiSessions')
    .doc(sessionId)
    .collection('messages');
    
  const snapshot = await messagesQuery.get();
  
  const batch = db.batch();
  snapshot.docs.forEach(doc => {
    batch.delete(doc.ref);
  });
  
  await batch.commit();
}
```

### Scheduled Job Implementation

**Vercel Cron Job:**
```typescript
// app/api/cron/session-lifecycle/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { SessionLifecycleManager } from '@/lib/ai/sessionLifecycle';

export async function GET(request: NextRequest) {
  try {
    // Verify cron secret for security
    const authHeader = request.headers.get('authorization');
    if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }
    
    console.log('Starting session lifecycle cleanup...');
    
    const lifecycleManager = new SessionLifecycleManager();
    
    // Run archiving
    const archiveResult = await lifecycleManager.archiveOldSessions();
    
    // Run deletion
    const deleteResult = await lifecycleManager.deleteExpiredSessions();
    
    // Log results
    const summary = {
      timestamp: new Date().toISOString(),
      archive: archiveResult,
      deletion: deleteResult,
      totalDuration: archiveResult.duration + deleteResult.duration
    };
    
    console.log('Session lifecycle cleanup completed:', summary);
    
    return NextResponse.json(summary);
    
  } catch (error) {
    console.error('Session lifecycle cleanup failed:', error);
    
    return NextResponse.json(
      { 
        error: 'Cleanup failed', 
        message: error.message,
        timestamp: new Date().toISOString()
      },
      { status: 500 }
    );
  }
}
```

**vercel.json Configuration:**
```json
{
  "crons": [
    {
      "path": "/api/cron/session-lifecycle",
      "schedule": "0 2 * * *"
    }
  ]
}
```

### Error Handling and Retries

**Retry Logic:**
```typescript
class RetryableOperation {
  private maxAttempts: number;
  private baseDelay: number;
  
  constructor(maxAttempts: number = 3, baseDelay: number = 1000) {
    this.maxAttempts = maxAttempts;
    this.baseDelay = baseDelay;
  }
  
  async execute<T>(
    operation: () => Promise<T>,
    operationName: string
  ): Promise<T> {
    let lastError: Error;
    
    for (let attempt = 1; attempt <= this.maxAttempts; attempt++) {
      try {
        return await operation();
        
      } catch (error) {
        lastError = error as Error;
        
        if (attempt === this.maxAttempts) {
          console.error(`${operationName} failed after ${this.maxAttempts} attempts:`, error);
          throw error;
        }
        
        const delay = this.baseDelay * Math.pow(2, attempt - 1); // Exponential backoff
        console.warn(`${operationName} attempt ${attempt} failed, retrying in ${delay}ms:`, error);
        
        await this.sleep(delay);
      }
    }
    
    throw lastError!;
  }
  
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

### Monitoring and Metrics

**Metrics Collection:**
```typescript
interface LifecycleMetrics {
  sessionsArchived: number;
  sessionsDeleted: number;
  totalErrors: number;
  averageProcessingTime: number;
  lastCleanupTime: number;
  storageUsage: {
    totalSessions: number;
    activeSessions: number;
    archivedSessions: number;
    estimatedSize: number;
  };
}

class LifecycleMonitor {
  private metrics: LifecycleMetrics;
  
  constructor() {
    this.metrics = this.initializeMetrics();
  }
  
  async collectMetrics(): Promise<LifecycleMetrics> {
    const storageUsage = await this.getStorageUsage();
    
    this.metrics = {
      ...this.metrics,
      storageUsage,
      lastCleanupTime: Date.now()
    };
    
    return this.metrics;
  }
  
  private async getStorageUsage(): Promise<LifecycleMetrics['storageUsage']> {
    // Query Firestore for session counts
    const totalSessions = await aiSessionsRepo.getSessionCount();
    const activeSessions = await aiSessionsRepo.getActiveSessionCount();
    const archivedSessions = await aiSessionsRepo.getArchivedSessionCount();
    
    // Estimate storage size (rough calculation)
    const estimatedSize = totalSessions * 1024; // Assume 1KB per session on average
    
    return {
      totalSessions,
      activeSessions,
      archivedSessions,
      estimatedSize
    };
  }
  
  logMetrics(): void {
    console.log('Session Lifecycle Metrics:', {
      timestamp: new Date().toISOString(),
      metrics: this.metrics
    });
  }
}
```

### Source Tree
```
app/api/cron/
└── session-lifecycle/
    └── route.ts          # NEW: Scheduled cleanup job

lib/ai/
├── sessionLifecycle.ts   # NEW: Lifecycle management
├── lifecycleMonitor.ts   # NEW: Metrics and monitoring
└── retryableOperation.ts # NEW: Retry logic

lib/db/
└── aiSessionsRepo.ts    # MODIFIED: Add lifecycle queries
```

### Testing

**Test Location:** `lib/ai/sessionLifecycle.test.ts`

**Test Coverage:**
- Session archiving with various timestamps
- Session deletion with different retention periods
- Batch processing operations
- Error handling and retry logic
- Metrics collection and monitoring

**Example Test:**
```typescript
describe('SessionLifecycleManager', () => {
  it('archives sessions after inactivity period', async () => {
    const manager = new SessionLifecycleManager();
    
    // Create test sessions with different lastMessageAt timestamps
    const oldSession = {
      id: 'old-session',
      lastMessageAt: Date.now() - (8 * 24 * 60 * 60 * 1000) // 8 days ago
    };
    
    const recentSession = {
      id: 'recent-session',
      lastMessageAt: Date.now() - (2 * 24 * 60 * 60 * 1000) // 2 days ago
    };
    
    const result = await manager.archiveOldSessions();
    
    expect(result.archived).toBe(1); // Only old session should be archived
    expect(result.errors).toBe(0);
  });
});
```

### Performance Considerations
- Process sessions in batches to avoid memory issues
- Use efficient Firestore queries with proper indexes
- Implement circuit breaker for repeated failures
- Monitor cleanup job execution time

### Dependencies
- aiSessionsRepo from Story 13.1
- Vercel Cron (or Cloud Functions)
- Firestore batch operations

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-13 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent*

### Debug Log References
_To be populated by dev agent*

### Completion Notes List
_To be populated by dev agent*

### File List
_To be populated by dev agent*

## QA Results
_To be populated by QA agent*
