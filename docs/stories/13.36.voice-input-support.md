# Story 13.36: Voice Input Support

## Status
ðŸ“‹ Planned

## Story
**As a** user who prefers speaking over typing,
**I want** to use voice input to create my case,
**so that** I can provide information hands-free and more naturally.

## Acceptance Criteria

1. Microphone button visible in chat input area
2. Uses Web Speech API or Whisper API for transcription
3. Real-time transcription display as user speaks
4. Stop button to end recording
5. Transcribed text appears in input field (editable before sending)
6. Works on mobile devices
7. Handles background noise reasonably
8. Permission request for microphone access
9. Visual indicator when recording (red dot/pulse animation)
10. Accessible (keyboard shortcut, clear labels)

## Tasks / Subtasks

- [ ] Task 1: Add microphone UI (AC: 1, 9, 10)
  - [ ] Microphone button with icon
  - [ ] Recording indicator animation
  - [ ] Stop button
  - [ ] Keyboard shortcut (Cmd/Ctrl + Shift + V)

- [ ] Task 2: Implement speech-to-text (AC: 2, 7)
  - [ ] Choose API (Web Speech vs Whisper)
  - [ ] Handle microphone permissions (AC: 8)
  - [ ] Stream audio for transcription
  - [ ] Handle errors gracefully

- [ ] Task 3: Real-time transcription display (AC: 3, 5)
  - [ ] Show transcription as it happens
  - [ ] Update input field
  - [ ] Allow editing before send

- [ ] Task 4: Mobile optimization (AC: 6)
  - [ ] Test on iOS and Android
  - [ ] Handle different browser implementations
  - [ ] Optimize for mobile microphones

- [ ] Task 5: Testing (AC: All)
  - [ ] Test with clear audio
  - [ ] Test with background noise
  - [ ] Test on multiple devices
  - [ ] Accessibility testing

## Dev Notes

### Web Speech API (Free, Browser-based)

```typescript
const recognition = new window.webkitSpeechRecognition();
recognition.continuous = true;
recognition.interimResults = true;

recognition.onresult = (event) => {
  const transcript = Array.from(event.results)
    .map((result) => result[0].transcript)
    .join('');

  setInputValue(transcript);
};

recognition.start();
```

### Whisper API (More accurate, costs $)

```typescript
async function transcribeAudio(audioBlob: Blob) {
  const formData = new FormData();
  formData.append('file', audioBlob, 'audio.webm');
  formData.append('model', 'whisper-1');

  const response = await openai.audio.transcriptions.create({
    file: audioBlob,
    model: 'whisper-1'
  });

  return response.text;
}
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-16 | 1.0 | Initial story creation | Product Team |

