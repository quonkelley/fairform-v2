# Story 13.8: Conversation Summarization

## Status
Draft

## Story
**As a** FairForm developer,
**I want** automatic conversation summarization to keep AI prompts efficient,
**so that** long conversations don't exceed token limits while maintaining context.

## Acceptance Criteria

1. System automatically summarizes older conversation history when it exceeds limits
2. Summarization preserves key topics and decisions made
3. Summary is generated using AI and stored with session metadata
4. System maintains sliding window of recent messages (last 10-15 messages)
5. Summarization triggers when conversation exceeds 50 messages or 8000 tokens
6. Summary includes case-related decisions and user preferences discovered
7. System handles summarization failures gracefully with fallback strategies
8. Unit tests cover summarization logic and edge cases

## Tasks / Subtasks

- [ ] Task 1: Create summarization service (AC: 1, 3)
  - [ ] Create `lib/ai/summarization.ts`
  - [ ] Implement summarizeConversation function
  - [ ] Add conversation analysis for key topics
  - [ ] Store summary in session metadata
  - [ ] Handle OpenAI API calls for summarization

- [ ] Task 2: Implement sliding window logic (AC: 4)
  - [ ] Create getSlidingWindow function for message selection
  - [ ] Keep last 10-15 messages in full detail
  - [ ] Implement token counting for message batches
  - [ ] Add logic to determine when summarization is needed

- [ ] Task 3: Add summarization triggers (AC: 5)
  - [ ] Monitor conversation length (message count)
  - [ ] Monitor token usage estimates
  - [ ] Trigger summarization at thresholds
  - [ ] Add configuration for trigger points

- [ ] Task 4: Implement topic extraction (AC: 2, 6)
  - [ ] Extract key topics from conversation
  - [ ] Identify case-related decisions
  - [ ] Capture user preferences and settings
  - [ ] Preserve important legal guidance given

- [ ] Task 5: Add AI-powered summarization (AC: 3)
  - [ ] Create summarization prompts for OpenAI
  - [ ] Implement structured summary format
  - [ ] Handle summarization API errors
  - [ ] Add retry logic for summarization calls

- [ ] Task 6: Implement graceful error handling (AC: 7)
  - [ ] Handle OpenAI summarization failures
  - [ ] Implement fallback to simple truncation
  - [ ] Add logging for summarization issues
  - [ ] Ensure conversation continues on errors

- [ ] Task 7: Update session metadata (AC: 3)
  - [ ] Add summary field to AISession interface
  - [ ] Store summarization timestamp
  - [ ] Track summarization version/quality
  - [ ] Update session when summary is created

- [ ] Task 8: Create comprehensive tests (AC: 8)
  - [ ] Test summarization triggers
  - [ ] Test sliding window logic
  - [ ] Test topic extraction
  - [ ] Test error handling scenarios
  - [ ] Mock OpenAI summarization API

## Dev Notes

### Architecture Context
[Source: docs/epic-13-unified-architecture-specification.md]

Conversation summarization is **critical for performance** - it prevents token bloat while preserving important context. The system uses a **sliding window approach** with AI-powered summarization of older content.

**Key Design Decisions:**
- Sliding window of recent messages (10-15 messages)
- AI-powered summarization for older content
- Topic extraction and decision preservation
- Graceful fallback on summarization failures
- Token-aware triggering

### Summarization Strategy

**Message Organization:**
```typescript
interface ConversationState {
  recentMessages: AIMessage[];    // Last 10-15 messages (full detail)
  summary: ConversationSummary;   // Summarized older content
  totalTokens: number;           // Estimated token count
  lastSummarizedAt: number;      // Timestamp of last summarization
}

interface ConversationSummary {
  topics: string[];              // Key topics discussed
  decisions: Decision[];         // Important decisions made
  userPreferences: object;       // User preferences discovered
  legalGuidance: string[];       // Legal guidance provided
  summaryText: string;           // Concise narrative summary
  messageCount: number;          // Number of messages summarized
  createdAt: number;            // When summary was created
}
```

### Sliding Window Implementation

**Window Management:**
```typescript
const SLIDING_WINDOW_SIZE = 12;  // Keep last 12 messages
const SUMMARIZATION_THRESHOLD = 50; // Trigger at 50 messages
const TOKEN_THRESHOLD = 8000;    // Trigger at 8000 tokens

function getSlidingWindow(messages: AIMessage[]): ConversationState {
  if (messages.length <= SLIDING_WINDOW_SIZE) {
    return {
      recentMessages: messages,
      summary: null,
      totalTokens: estimateTokens(messages),
      lastSummarizedAt: 0
    };
  }
  
  const recentMessages = messages.slice(-SLIDING_WINDOW_SIZE);
  const olderMessages = messages.slice(0, -SLIDING_WINDOW_SIZE);
  
  return {
    recentMessages,
    summary: null, // Will be populated by summarization
    totalTokens: estimateTokens(recentMessages),
    lastSummarizedAt: 0
  };
}
```

### Summarization Triggers

**Trigger Logic:**
```typescript
function shouldSummarize(session: AISession, messageCount: number, tokenCount: number): boolean {
  // Always summarize if we exceed thresholds
  if (messageCount > SUMMARIZATION_THRESHOLD) return true;
  if (tokenCount > TOKEN_THRESHOLD) return true;
  
  // Summarize if it's been a while since last summary
  const timeSinceLastSummary = Date.now() - (session.lastSummarizedAt || 0);
  if (timeSinceLastSummary > 24 * 60 * 60 * 1000) return true; // 24 hours
  
  return false;
}

function estimateTokens(messages: AIMessage[]): number {
  // Rough estimation: 1 token â‰ˆ 4 characters
  const totalChars = messages.reduce((sum, msg) => sum + msg.content.length, 0);
  return Math.ceil(totalChars / 4);
}
```

### AI Summarization Implementation

**Summarization Prompts:**
```typescript
const SUMMARIZATION_PROMPT = `
You are analyzing a legal assistance conversation to create a concise summary.

Conversation to summarize:
{conversation}

Please provide a structured summary in JSON format:
{
  "topics": ["topic1", "topic2", ...],
  "decisions": [
    {
      "decision": "description of decision made",
      "context": "why this decision was important",
      "timestamp": "when it was made"
    }
  ],
  "userPreferences": {
    "tone": "preferred communication style",
    "complexity": "preferred explanation level",
    "focus": "user's main concerns"
  },
  "legalGuidance": [
    "key legal guidance provided",
    "important legal concepts explained"
  ],
  "summaryText": "concise narrative of the conversation",
  "keyOutcomes": ["what was accomplished", "next steps identified"]
}

Focus on:
- Legal topics and decisions made
- User preferences and communication style
- Important guidance provided
- Case-related outcomes

Keep the summary concise but comprehensive.
`;

async function summarizeConversation(messages: AIMessage[]): Promise<ConversationSummary> {
  const conversationText = messages
    .map(msg => `${msg.author}: ${msg.content}`)
    .join('\n');
  
  const prompt = SUMMARIZATION_PROMPT.replace('{conversation}', conversationText);
  
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: 'You are a legal assistant conversation analyzer. Create structured summaries of legal assistance conversations.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.1, // Low temperature for consistent structure
      max_tokens: 1000
    });
    
    const summaryData = JSON.parse(response.choices[0].message.content || '{}');
    
    return {
      topics: summaryData.topics || [],
      decisions: summaryData.decisions || [],
      userPreferences: summaryData.userPreferences || {},
      legalGuidance: summaryData.legalGuidance || [],
      summaryText: summaryData.summaryText || '',
      keyOutcomes: summaryData.keyOutcomes || [],
      messageCount: messages.length,
      createdAt: Date.now()
    };
  } catch (error) {
    console.error('Summarization failed:', error);
    throw new Error('Failed to summarize conversation');
  }
}
```

### Topic Extraction

**Topic Analysis:**
```typescript
function extractTopics(messages: AIMessage[]): string[] {
  const topicKeywords = {
    'eviction': ['eviction', 'tenant', 'landlord', 'rent', 'lease'],
    'small_claims': ['small claims', 'money', 'debt', 'payment', 'contract'],
    'family_law': ['divorce', 'custody', 'child support', 'family'],
    'employment': ['job', 'work', 'employer', 'wage', 'discrimination'],
    'document_help': ['document', 'form', 'filing', 'paperwork'],
    'court_process': ['court', 'hearing', 'trial', 'judge', 'procedure']
  };
  
  const allText = messages.map(m => m.content.toLowerCase()).join(' ');
  const foundTopics: string[] = [];
  
  for (const [topic, keywords] of Object.entries(topicKeywords)) {
    if (keywords.some(keyword => allText.includes(keyword))) {
      foundTopics.push(topic);
    }
  }
  
  return foundTopics;
}
```

### Integration with Session Management

**Session Updates:**
```typescript
async function updateSessionWithSummary(
  sessionId: string, 
  summary: ConversationSummary
): Promise<void> {
  await aiSessionsRepo.updateSession(sessionId, {
    summary: summary,
    lastSummarizedAt: Date.now(),
    updatedAt: Date.now()
  });
}

// Add to AISession interface
interface AISession {
  // ... existing fields
  summary?: ConversationSummary;
  lastSummarizedAt?: number;
}
```

### Error Handling and Fallbacks

**Graceful Degradation:**
```typescript
async function summarizeWithFallback(messages: AIMessage[]): Promise<ConversationSummary> {
  try {
    return await summarizeConversation(messages);
  } catch (error) {
    console.warn('AI summarization failed, using simple fallback:', error);
    
    // Fallback: Simple topic extraction and truncation
    return {
      topics: extractTopics(messages),
      decisions: [],
      userPreferences: {},
      legalGuidance: [],
      summaryText: `Conversation about ${extractTopics(messages).join(', ')}. ${messages.length} messages discussed various legal topics.`,
      keyOutcomes: [],
      messageCount: messages.length,
      createdAt: Date.now()
    };
  }
}
```

### Source Tree
```
lib/ai/
â”œâ”€â”€ summarization.ts       # NEW: Summarization service
â”œâ”€â”€ contextBuilder.ts      # EXISTING: From Story 13.3
â”œâ”€â”€ types.ts              # MODIFIED: Add summary fields
â””â”€â”€ schemas.ts            # EXISTING: From Story 13.2

lib/db/
â””â”€â”€ aiSessionsRepo.ts     # MODIFIED: Add summary support
```

### Context Builder Integration

**Updated Context Building:**
```typescript
// In contextBuilder.ts
function buildContextWithSummary(session: AISession, recentMessages: AIMessage[]): AIPromptContext {
  const baseContext = buildContext(session.userId, session.caseId, session.id);
  
  // Add conversation summary if available
  if (session.summary) {
    baseContext.conversationSummary = {
      topics: session.summary.topics,
      decisions: session.summary.decisions,
      userPreferences: session.summary.userPreferences,
      summaryText: session.summary.summaryText
    };
  }
  
  // Add recent messages
  baseContext.recentMessages = recentMessages.slice(-10); // Last 10 messages
  
  return baseContext;
}
```

### Testing

**Test Location:** `lib/ai/summarization.test.ts`

**Test Coverage:**
- Sliding window logic
- Summarization triggers
- Topic extraction
- AI summarization API integration
- Error handling and fallbacks
- Session updates

**Example Test:**
```typescript
describe('summarization', () => {
  it('creates sliding window correctly', () => {
    const messages = Array.from({ length: 20 }, (_, i) => ({
      id: `msg-${i}`,
      content: `Message ${i}`,
      author: 'user' as const,
      createdAt: Date.now() + i * 1000
    }));
    
    const window = getSlidingWindow(messages);
    
    expect(window.recentMessages).toHaveLength(12); // SLIDING_WINDOW_SIZE
    expect(window.recentMessages[0].content).toBe('Message 8'); // Last 12 messages
  });
  
  it('triggers summarization at message threshold', () => {
    const session = { lastSummarizedAt: 0 };
    const messageCount = 51; // Above threshold
    const tokenCount = 1000;
    
    expect(shouldSummarize(session, messageCount, tokenCount)).toBe(true);
  });
  
  it('handles summarization errors gracefully', async () => {
    // Mock OpenAI API to throw error
    vi.mocked(openai.chat.completions.create).mockRejectedValue(new Error('API Error'));
    
    const messages = [
      { id: '1', content: 'Hello', author: 'user', createdAt: Date.now() }
    ];
    
    const summary = await summarizeWithFallback(messages);
    
    expect(summary.summaryText).toContain('Conversation about');
    expect(summary.topics).toBeDefined();
  });
});
```

### Performance Considerations
- Summarization runs asynchronously
- Cache summarization results
- Batch summarization requests
- Monitor OpenAI API usage and costs

### Dependencies
- openai (existing)
- aiSessionsRepo from Story 13.1
- contextBuilder from Story 13.3

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-13 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent*

## QA Results
_To be populated by QA agent_
